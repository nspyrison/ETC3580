---
title: "ETC3580: Advanced Statistical Modelling"
author: "Week 5: Count responses"
fontsize: 14pt
output:
  beamer_presentation:
    theme: metropolis
    fig_height: 4.5
    fig_width: 7
    highlight: tango
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, warning=FALSE, message=FALSE,
  dev.args=list(bg=grey(0.9), pointsize=11))
library(faraway)
library(tidyverse)
```

# Poisson regression

## Poisson distribution
\fontsize{14}{16}\sf

Let $Y=$ number of events in given time interval. If events independent, and prob of event proportional to length of interval, then $Y$ is Poisson distributed.

\begin{block}{Poisson$(\mu)$ distribution}
$$ P(Y=y) = \frac{e^{-\mu}\mu^y}{y!}$$
\end{block}

 * $\E(Y)=\V(Y)=\mu$
 * If $Y\sim B(n,p)$, then $Y \approx \text{Poisson}(np)$  for small $p/n$.
 * If $Y\sim \text{Poisson}(\mu)$, then $Y\approx N(\mu,\mu)$ for large $\mu$.
 * Poisson$(\mu_1)$ + Poisson$(\mu_1) \sim$ Poisson$(\mu_1+\mu_2)$.

## Poisson distribution

```{r}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.show = "animate")
mulist <- c(seq(0.1,1,by=0.1),seq(2,20,by=1))
x <- 0:22
nx <- length(x)
nmu <- length(mulist)
df <- tibble(
    x=rep(x,nmu),
    mu=rep(mulist, rep(nx,nmu)))
df <- mutate(df, prob=dpois(x,mu))

for(i in 1:nmu)
{
  pdf(file=paste("figs/poisson",i,".pdf",sep=""), width=15/2.54, height=10/2.54)
  p <- ggplot(filter(df, mu==mulist[i]), aes(x=x, y=prob)) +
    geom_bar(stat='identity') +
    ggtitle(paste("Poisson(",mulist[i],")",sep="")) +
    xlab("y") + ylab("Probability(y)") + ylim(0,.91)
  print(p)
  crop::dev.off.crop()
}
```

\centerline{\animategraphics[controls,buttonsize=0.3cm,width=11.5cm]{6}{"figs/poisson"}{1}{20}}


## Regression with count data

Suppose response $Y$ is a count (0,1,2,\dots).

 * If count is bounded and bound is small, use binomial regression.
 * If min count is large, use normal approximation.
 * Otherwise, use Poisson or negative binomial.

## Poisson regression

\begin{block}{}\vspace*{-0.4cm}
\begin{align*}
&y_i \sim \text{Poisson}(\mu_i) \\
&\log(\mu_i) = \eta_i = \beta_0 + \beta_1 x_{i,1} + \dots + \beta_q x_{i,q}
\end{align*}
\end{block}

 * Log link function forces positive mean.\pause
 * Likelihood: $\displaystyle L = \prod_{i=1}^n \frac{\exp^{-\mu_i}\mu_i^{y_i}}{y_i!}$\pause
\begin{align*}
\log L &= \sum_{i=1}^n \left[-\mu_i + y_i\log(\mu_i) - \log(y_i!)\right] \\
       &= \sum_{i=1}^n \left[-\exp(\bm{x}_i'\bm{\beta}) + y_i\bm{x}_i'\bm{\beta} - \log(y_i!)\right]
\end{align*}\pause\vspace*{-0.5cm}

```r
fit <- glm(y ~ x1 + x2,
  family='poisson', data)
```

## Deviance
\vspace*{-0.7cm}
\begin{align*}
D = -2\log L &= -2\sum_{i=1}^n \left[-\hat\mu_i + y_i\log(\hat\mu_i) - \log(y_i!)\right] \\
    & = 2\sum_{i=1}^n (y_i \log(y_i/\hat{\mu}_i) - (y_i - \hat{\mu}_i))
\end{align*}\pause

* Check distributional assumptions by comparing $D$ against $\chi^2$
* Compare changes in deviance using a $\chi^2$ test as for binomial regression.
* Use profile likelihood to find confidence intervals for parameters.
* Common for a model to be "over-dispersed".

## Dispersed Poisson model

When model is over-dispersed (variance too large):

 * estimates of $\bm{\beta}$ consistent, but standard errors incorrect.
 * could correct model using quasi-Poisson model or negative binomial model.

# Quasi-Poisson regression

## Quasi-Poisson models

Assumes:
$$ Y \in \{0,1,2,\dots\}\qquad
\E(Y) = \mu,\qquad \text{Var}(Y)=\phi\mu$$

```r
fit <- glm(y ~ x1 + x2,
  family='quasipoisson', data)
```

 * Use $F$-tests not $\chi^2$ tests when using quasi-Poisson models
 * Overdispersion parameter $\phi$ represents the variance inflation

# Negative binomial regression

## Negative binomial distribution

\begin{block}{}
In series of independent trials, each with prob $p$ of success, let $Z$ be number of trials until $k$th success.
$$P(Z=z) = {z-1 \choose k-1} p^k (1-p)^{z-k}, \qquad z=k,k+1,\dots$$
\end{block}

* $k=1$ gives the *geometric* distribution.
* The NegBin distribution also arises when $Y\sim \text{Poisson}(\lambda)$ and $\lambda\theta\sim\gamma$ for some constant $\theta$.
* For negative binomial regression, we model $Y=Z-k$.
* $\E(Y)=\mu=k(1-p)/p$ and $\V(Y)=\mu+\mu^2/k$.
* $p = k/(k+\mu)$

## Negative binomial regression
\fontsize{13}{14}\sf

\begin{block}{}
$Y_i \sim \text{NegBin}-k$ with mean $\mu_i$ and variance $\mu_i+\mu_i^2/k$.
$$\eta_i = \log\left(\frac{\mu_i}{\mu_i+k}\right) =
 \beta_0 + \beta_1 x_{i,1} + \dots + \beta_q x_{i,q}$$
\end{block}

 * $k$ (the "dispersion" parameter) is usually estimated along with the coefficients by MLE:
$$ L = \prod_{i=1}^n {y_i+k-1 \choose k-1} p_i^k (1-p_i)^{y_i}$$\vspace*{-0.3cm}

\begin{align*}
\log L &= \sum_{i=1}^n \Bigg(y_i \log\left(\frac{\mu_i}{\mu_i+k}\right) - k log(1+\mu_i/k) \\
& \mbox{} \hspace*{1cm} +\sum_{j=0}^{y_i-1} \log(j+k) - \log(y_i!)\Bigg)
\end{align*}


## Negative binomial regression

```r
# Specified k
fit <- glm(y ~ x1 + x2,
  family=negative.binomial(k), data)

# Estimated k
fit <- MASS::glm.nb(y ~ x1 + x2, data)
```


# Zero inflated count models

## Zero inflated count models

\alert{Examples of zero-inflated data:}

 * Number of insurance claims for each account
 * Number of arrests for criminal offences for each individual
 * Number of articles written by PhD students

Over-dispersed models do not deal adequately with this type of data.


## Zero-inflated count models

\alert{Solution 1}: Hurdle model

 * Model for probability of zero (logistic).
 * Model for non-zero counts (truncated Poisson).
\begin{align*}
  P(Y=0) &= p \\
  P(Y=j) &= \frac{1-p}{1-f(0)} f(j), \qquad j>0
\end{align*}

 * $p$ is probability of zero; $f$ is Poisson probability.
 * Two sets of coefficients for the two parts of the model.

```r
fit <- pscl::hurdle(y ~ x1 + x2, data)
```

## Zero-inflated count models

\alert{Solution 2}: Mixture model

 * Model for probability of always zero (logistic).
 * Model for counts (regular Poisson).
\begin{align*}
  P(Y=0) &= p + (1-p) f(0) \\
  P(Y=j) &= (1-p) f(j), \qquad j>0
\end{align*}

 * $p$ is probability of zero; $f$ is Poisson probability.
 * Two sets of coefficients for the two parts of the model.

```r
fit <- pscl::zeroinfl(y ~ x1 + x2, data)
```


## Zero-inflated count models

 * Often difficult to select between these -- what makes most sense for the application?
 * Can have different predictors for the two sub-models:

    ```r
    fit <- zeroinfl(y ~ x1 + x2 | x3, data)
    ```

     count model before the `|` and zero model after.


